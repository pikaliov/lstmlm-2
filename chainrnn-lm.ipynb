{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from chainer import cuda, Function, FunctionSet, gradient_check, Variable, optimizers\n",
    "import chainer.functions as F\n",
    "from textblob import TextBlob\n",
    "import time\n",
    "from itertools import izip_longest\n",
    "VOCAB_SIZE = 150\n",
    "DROPOUT = 0.1\n",
    "CLIP = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "def file_split_generator(fn,n,yieldsize):\n",
    "    size = os.path.getsize(fn)\n",
    "    cutoffs = [i * size/n for i in xrange(n)]\n",
    "    offset = 0\n",
    "    #open as ascii for now; utf-8 makes this not work\n",
    "    with open(fn,\"r\") as f:\n",
    "        while True:\n",
    "            batches = []\n",
    "            result = []\n",
    "            if cutoffs[0] + offset + yieldsize >= cutoffs[1]:\n",
    "                raise StopIteration\n",
    "            for cutoff in cutoffs:\n",
    "                f.seek(cutoff + offset)\n",
    "                result.append(f.read(yieldsize))\n",
    "            offset += yieldsize\n",
    "            yield result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "from collections import Counter\n",
    "def get_vocabulary(fn, keep=200):\n",
    "    char_to_index = {}\n",
    "    count = 0\n",
    "    text = []\n",
    "    frequencies = Counter()\n",
    "    with open(fn,\"r\") as f:\n",
    "        for line in f:\n",
    "            text.append(line)\n",
    "            for c in line:\n",
    "                frequencies[c] += 1\n",
    "    print len(frequencies)\n",
    "                \n",
    "    #trim rare chars\n",
    "    char_to_index = {k:i for i,(k,_) in enumerate(frequencies.most_common())}\n",
    "    kept_set = set(c for c,_ in frequencies.most_common(keep))\n",
    "    index_to_char = {v:k for k,v in char_to_index.iteritems() if k in kept_set}\n",
    "    char_to_index = {k:v if k in kept_set else keep for k,v in char_to_index.iteritems()}\n",
    "    return char_to_index,index_to_char\n",
    "\n",
    "char_to_index,index_to_char = get_vocabulary(\"data/response_train.txt\", keep=VOCAB_SIZE-1)\n",
    "\n",
    "with open(\"data/response_valid.txt\",\"r\") as f:\n",
    "    validation_texts = [line[:-1] for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def char_to_onehot(c,char_to_index,vocab_size):\n",
    "    return np.array((char_to_index[c],),dtype=np.int32)\n",
    "\n",
    "def vector_to_char(v, temp=1.0):\n",
    "    v = v.ravel()\n",
    "    exponentiated = np.exp(v/temp)\n",
    "    softmax = exponentiated/ exponentiated.sum()\n",
    "    cutoff = np.random.random()\n",
    "    for i,val in enumerate(softmax):\n",
    "        cutoff -= val\n",
    "        if cutoff <= 0:\n",
    "            break\n",
    "    try:\n",
    "        return index_to_char[i]\n",
    "    except KeyError:\n",
    "        return \"<OOV>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_units = 500\n",
    "model = FunctionSet(\n",
    "    embed = F.EmbedID(VOCAB_SIZE, n_units),\n",
    "    l1_x = F.Linear(n_units, 4 * n_units), \n",
    "    l1_h = F.Linear(n_units, 4 * n_units),\n",
    "    l2_x = F.Linear(n_units, 4 * n_units), \n",
    "    l2_h = F.Linear(n_units, 4 * n_units),\n",
    "    l3 = F.Linear(n_units, VOCAB_SIZE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import chainer.computational_graph as c\n",
    "\n",
    "def forward_one_step(x_data, y_data, state, train=True):\n",
    "    x = Variable(x_data, volatile=not train)\n",
    "    t = Variable(y_data, volatile=not train)\n",
    "    \n",
    "    h0 = model.embed(x)\n",
    "    \n",
    "    h1_in = model.l1_x(F.dropout(h0, ratio=DROPOUT, train=train)) + model.l1_h(state['h1'])\n",
    "    c1, h1 = F.lstm(state['c1'], h1_in)\n",
    "    h2_in = model.l2_x(F.dropout(h1, ratio=DROPOUT, train=train)) + model.l2_h(state['h2'])\n",
    "    c2, h2 = F.lstm(state['c2'], h2_in)\n",
    "    y = model.l3(F.dropout(h2, ratio=DROPOUT, train=train))\n",
    "    \n",
    "    state = {'c1': c1, 'h1': h1, 'c2': c2, 'h2': h2}\n",
    "    return state, F.softmax_cross_entropy(y, t), y\n",
    "\n",
    "def make_initial_state(batchsize=1, train=True):\n",
    "    return {name: Variable(np.zeros((batchsize, n_units), dtype=np.float32), volatile=not train)\n",
    "            for name in ('c1', 'h1', 'c2', 'h2')}\n",
    "\n",
    "def forward_batch(texts, targets, train=True, init_state=None):\n",
    "    if init_state is None:\n",
    "        state = make_initial_state(batchsize=len(texts), train=train)\n",
    "    else:\n",
    "        state = init_state\n",
    "    \n",
    "    #zip will truncate to the shortest length\n",
    "    zipped = zip(*texts)\n",
    "    zipped_targets = zip(*targets)\n",
    "    error = np.zeros((), dtype=np.float32)\n",
    "    for i in xrange(0,len(zipped)):\n",
    "        next_chunk = np.array([char_to_index[c] for c in zipped[i]], dtype=np.int32)\n",
    "        next_targets = np.array([char_to_index[c] for c in zipped_targets[i]], dtype=np.int32)\n",
    "        state, char_errors, _ = forward_one_step(next_chunk, next_targets, state, train=train)\n",
    "        error += char_errors\n",
    "    return error/(len(zipped)), state\n",
    "\n",
    "def grouper(iterable, n, fillvalue=None):\n",
    "    args = [iter(iterable)] * n\n",
    "    return izip_longest(*args, fillvalue=fillvalue)\n",
    "\n",
    "def evaluate(dataset):\n",
    "    error = 0\n",
    "    for i,group in enumerate(grouper(dataset, 10)):\n",
    "        group = [g for g in group if g is not None and len(g) > 2]\n",
    "        source = [g[:-1] for g in group]\n",
    "        target = [g[1:] for g in group]\n",
    "        error += forward_batch(source,target,train=False)[0]\n",
    "    return error.data / len(dataset)\n",
    "\n",
    "def train(train_fn, valid, epochs, opt, batchsize=10, eval_count=2000, seq_length=100):\n",
    "    total_error = Variable(np.zeros((), dtype=np.float32), volatile=False)\n",
    "    state = make_initial_state(batchsize=1, train=True)\n",
    "    current_time = time.time()\n",
    "    sentences = 0\n",
    "    batch_error = 0\n",
    "    iterations = 0\n",
    "    accumulated = []\n",
    "    state = None\n",
    "    for e in xrange(epochs):\n",
    "        for i,batch in enumerate(file_split_generator(train_fn, batchsize, seq_length)):\n",
    "            iterations += 1\n",
    "            if random.random() < 0.05:\n",
    "                #make the model learn how to handle the stateless situation\n",
    "                #i assume there's a much better way to do this\n",
    "                state = None \n",
    "            loss,state = forward_batch([text[:-1] for text in batch], [text[1:] for text in batch], train=True, init_state=state)\n",
    "            print i,loss.data\n",
    "            accumulated = []\n",
    "            batch_error += loss.data\n",
    "            opt.zero_grads()\n",
    "            loss.backward()\n",
    "            loss.unchain_backward()\n",
    "            opt.clip_grads(CLIP)\n",
    "            opt.update()\n",
    "            if iterations%eval_count == 0:\n",
    "                valid_error = evaluate(valid)\n",
    "                print \"({}.{}) - {:.6f} (took: {:.2f}s): {}\".format(e, i, valid_error,time.time() - current_time,sample_sentence())\n",
    "                current_time = time.time()\n",
    "                batch_error = 0\n",
    "            \n",
    "def get_graph(text):\n",
    "    loss = forward_batch([text],[text])\n",
    "    g = c.build_computational_graph([loss])\n",
    "    return g\n",
    "               \n",
    "def sample_sentence(seed='A',length=50,temp=1):\n",
    "    state = make_initial_state(batchsize=1, train=False)\n",
    "    string = []\n",
    "    for s in seed:\n",
    "        next_char = s\n",
    "        in_c = char_to_onehot(next_char,char_to_index,VOCAB_SIZE)\n",
    "        state,_,next_vals = forward_one_step(in_c, in_c, state, train=False)\n",
    "        string.append(s)\n",
    "    for i in xrange(length):\n",
    "        next_char = string[-1]\n",
    "        if next_char == \"<OOV>\":\n",
    "            next_char = \" \"\n",
    "        in_c = char_to_onehot(next_char,char_to_index,VOCAB_SIZE)\n",
    "        state,_,next_vals = forward_one_step(in_c, in_c, state, train=False)\n",
    "        string.append(vector_to_char(next_vals.data,temp=temp))\n",
    "    return \"\".join(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'optimizers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ec823ce18a7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#optimizer = optimizers.SGD(lr=0.02)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/response_train.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_texts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'optimizers' is not defined"
     ]
    }
   ],
   "source": [
    "#optimizer = optimizers.SGD(lr=0.02)\n",
    "optimizer = optimizers.Adam()\n",
    "optimizer.setup(model.collect_parameters())\n",
    "optimizer.zero_grads()\n",
    "train(\"data/response_train.txt\", validation_texts, 10, optimizer, batchsize=50, eval_count=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'le a a wenel mor to can and as in this acte and be '"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sentence(\"l\", temp=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
