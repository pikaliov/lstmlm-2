{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from chainer import cuda, Function, FunctionSet, gradient_check, Variable, optimizers\n",
    "import chainer.functions as F\n",
    "from textblob import TextBlob\n",
    "import time\n",
    "VOCAB_SIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "from collections import Counter\n",
    "def load_data(keep=200):\n",
    "    char_to_index = {}\n",
    "    count = 0\n",
    "    text = []\n",
    "    frequencies = Counter()\n",
    "    with codecs.open(\"responseText-0.txt\",\"r\",\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            text.append(line)\n",
    "            for c in line:\n",
    "                frequencies[c] += 1\n",
    "                \n",
    "    #trim rare chars\n",
    "    char_to_index = {k:i for i,(k,_) in enumerate(frequencies.most_common())}\n",
    "    kept_set = set(c for c,_ in frequencies.most_common(keep))\n",
    "    index_to_char = {v:k for k,v in char_to_index.iteritems() if k in kept_set}\n",
    "    char_to_index = {k:v if k in kept_set else keep for k,v in char_to_index.iteritems()}\n",
    "    return text,char_to_index,index_to_char\n",
    "texts,char_to_index,index_to_char = load_data(keep=VOCAB_SIZE-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def char_to_onehot(c,char_to_index,vocab_size):\n",
    "    #result = np.zeros((VOCAB_SIZE,),dtype=np.int32)\n",
    "    #result[char_to_index[c]] = 1\n",
    "    return np.array((char_to_index[c],),dtype=np.int32)\n",
    "\n",
    "def vector_to_char(v, temp=1.0):\n",
    "    v = v.ravel()\n",
    "    exponentiated = np.exp(v/temp)\n",
    "    softmax = exponentiated/ exponentiated.sum()\n",
    "    cutoff = np.random.random()\n",
    "    for i,val in enumerate(softmax):\n",
    "        cutoff -= val\n",
    "        \n",
    "        if cutoff <= 0:\n",
    "            break\n",
    "    try:\n",
    "        return index_to_char[i]\n",
    "    except KeyError:\n",
    "        return \"<OOV>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([30], dtype=int32)"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_to_onehot(u'\\n',char_to_index,VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_units = 300\n",
    "model = FunctionSet(\n",
    "    embed = F.EmbedID(VOCAB_SIZE, n_units),\n",
    "    l1_x = F.Linear(n_units, 4 * n_units), \n",
    "    l1_h = F.Linear(n_units, 4 * n_units),\n",
    "    l2_x = F.Linear(n_units, 4 * n_units), \n",
    "    l2_h = F.Linear(n_units, 4 * n_units),\n",
    "    l3 = F.Linear(n_units, VOCAB_SIZE)\n",
    ")\n",
    "optimizer = optimizers.SGD(lr=0.001)\n",
    "optimizer.setup(model.collect_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def forward_one_step(x_data, y_data, state, train=True):\n",
    "    x = Variable(x_data, volatile=not train)\n",
    "    t = Variable(y_data, volatile=not train)\n",
    "    \n",
    "    h0 = model.embed(x)\n",
    "    \n",
    "    h1_in = model.l1_x(F.dropout(h0, train=train)) + model.l1_h(state['h1'])\n",
    "    c1, h1 = F.lstm(state['c1'], h1_in)\n",
    "    h2_in = model.l2_x(F.dropout(h1, train=train)) + model.l2_h(state['h2'])\n",
    "    c2, h2 = F.lstm(state['c2'], h2_in)\n",
    "    y = model.l3(F.dropout(h2, train=train))\n",
    "    \n",
    "    state = {'c1': c1, 'h1': h1, 'c2': c2, 'h2': h2}\n",
    "    return state, F.softmax_cross_entropy(y, t), y\n",
    "\n",
    "def make_initial_state(batchsize=1, train=True):\n",
    "    return {name: Variable(np.zeros((batchsize, n_units), dtype=np.float32), volatile=not train)\n",
    "            for name in ('c1', 'h1', 'c2', 'h2')}\n",
    "\n",
    "def forward_batch(texts, targets, train=True):\n",
    "    state = make_initial_state(batchsize=len(texts), train=train)\n",
    "    \n",
    "    #zip will truncate to the shortest length\n",
    "    zipped = zip(*texts)\n",
    "    zipped_targets = zip(*targets)\n",
    "    error = np.zeros((), dtype=np.float32)\n",
    "    for i in xrange(0,len(zipped)):\n",
    "        next_chunk = np.array([char_to_index[c] for c in zipped[i]], dtype=np.int32)\n",
    "        next_targets = np.array([char_to_index[c] for c in zipped_targets[i]], dtype=np.int32)\n",
    "        state, char_errors, _ = forward_one_step(next_chunk, next_targets, state, train=train)\n",
    "        error += char_errors\n",
    "    return error/(len(zipped))\n",
    "\n",
    "def train(dataset, opt, batchsize=10):\n",
    "    total_error = Variable(np.zeros((), dtype=np.float32), volatile=False)\n",
    "    state = make_initial_state(batchsize=1, train=True)\n",
    "    current_time = time.time()\n",
    "    sentences = 0\n",
    "    batch_error = 0\n",
    "    accumulated = []\n",
    "    for i,post in enumerate(dataset):\n",
    "        if len(post) < 100:\n",
    "            #we'll be truncating the batch to the smallest post in it, so make sure none are too small\n",
    "            continue\n",
    "        accumulated.append(post)\n",
    "        if len(accumulated) == batchsize:\n",
    "            #TODO: ok this part could be better, right now i make the input and outputs the same length\n",
    "            #by chopping off the first and last letter respectively\n",
    "            loss = forward_batch([acc[:-1] for acc in accumulated], [acc[1:] for acc in accumulated], train=True)\n",
    "            accumulated = []\n",
    "            batch_error += loss.data\n",
    "            loss.backward()\n",
    "            loss.unchain_backward() #reset between batches - maybe we need this more often? not sure if it's doing anything here\n",
    "            #opt.clip_grads(clip)\n",
    "            opt.update()\n",
    "        if i%200 == 0:\n",
    "            print i/float(len(dataset)),sample_sentence(),time.time() - current_time,batch_error\n",
    "            current_time = time.time()\n",
    "            batch_error = 0\n",
    "               \n",
    "def sample_sentence(seed='A',length=50,temp=1):\n",
    "    state = make_initial_state(batchsize=1, train=False)\n",
    "    string = [seed]\n",
    "    for i in xrange(length):\n",
    "        next_char = string[-1]\n",
    "        if next_char == \"<OOV>\":\n",
    "            next_char = \" \"\n",
    "        in_c = char_to_onehot(next_char,char_to_index,VOCAB_SIZE)\n",
    "        state,_,next_vals = forward_one_step(in_c, in_c, state, train=False)\n",
    "        string.append(vector_to_char(next_vals.data,temp=temp))\n",
    "    return \"\".join(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02 And is is of can a chobreashas fe aterd eveciantese 12.4042401314 22.59795928\n",
      "0.04 Aty fin to thom posresile noc, wroverifidy aten diu 11.0946769714 19.6842820644\n",
      "0.06 Agttonsse I aronely are op that soces ins is ase in 14.6745350361 22.6206822395\n",
      "0.08 Abes con buto the srolitover, triton carnasoun and  13.30123806 22.1325075626\n",
      "0.1 At a rompedso 21D20A't to pread shave mot datare al 12.8401789665 22.0858845711\n",
      "0.12 Ar myf a rerglemy ariety a you on in to to shastsig 14.0450849533 22.2942943573\n",
      "0.14 Any a in thic at momen are prot that ecic the peat  12.1910228729 19.5227386951\n",
      "0.16 At stfresentse ea that pron of lea and sery to pow  16.2302150726 22.1350159645\n",
      "0.18 A it the the exassic renut wiise you crestre a coni 12.6032700539 21.7852401733\n",
      "0.2 A don ercthis ealt is ithat the nier suther a Aof o 13.1085960865 21.8892943859\n",
      "0.22 Adr your lidurs conal morty this loentt hast the in 15.1597008705 21.5839211941\n",
      "0.24 And are enmarsm yould tescropenfe care mish the lim 11.7064061165 21.9656238556\n",
      "0.3 Arresser 2. q<OOV>noto the w sithere it younk ind aln t 41.102533102 62.2756643295\n",
      "0.34 Anosyee hleacr nentnuciticios com, Mom very reay q<OOV> 26.2428991795 inf\n",
      "0.36 Ais be recopimeronterne infiting the in, twy with y 14.4405908585 21.8950808048\n",
      "0.38 Ars yla, with, is in and you sescoof solumill in te 12.6198132038 21.5341179371\n",
      "0.4 Ally a bonesmant yourfr, wagpent the havelsaf thims 11.0929071903 19.11388731\n",
      "0.42 A nasss carl soll cata to your of surentlniogitht h 15.1709518433 23.8963088989\n",
      "0.44 Atef this sulitive in derlit the ach thers inst arh 12.1444580555 21.5412857533\n",
      "0.46 Arst wase. Ritet thive a lecont ace as ise is the t 13.2609949112 21.4033837318\n",
      "0.48 Al sash suting the has astivenalt mysed and to lasi 15.5627148151 21.7189102173\n",
      "0.5 Ame abroourme suld anel you comy mooget a mase dell 11.4664621353 19.0852620602\n",
      "0.52 An bied the you gas to what lefirt ates that mupe b 13.4327259064 22.1626152992\n",
      "0.54 Ave ste hen remave you of lemy of prealnies Sitrid  12.2040920258 21.4507741928\n",
      "0.58 At the asd arged ituh shotion the com ususoh rearig 24.5947320461 40.2604753971\n",
      "0.6 Ar in a beentn to deend goapd is fralowates sublel  13.282047987 21.0473792553\n",
      "0.62 Aboutting the the is it tringent of a aree is the y 14.2400360107 21.1096966267\n",
      "0.64 Ar to mall 2dertelelo is hob of Phrilasst ad perpec 13.3401961327 inf\n",
      "0.66 At of to any ant ofteme disate reagib peald woult d 14.2555599213 20.8189005852\n",
      "0.68 Anstol stt I camint os tearscuaces as in marurvimes 14.2423021793 21.048085928\n",
      "0.72 Ans but muting a you stfenfinard menisionse alcmy n 25.9078040123 42.3431613445\n",
      "0.74 Ad hendsing onmses you ant a ditprede your rerdints 14.5150630474 21.3935778141\n",
      "0.76 Arlient leos have stertheer heacters and scon widef 13.0814681053 21.2339868546\n",
      "0.78 Aning is sorst the any rot con is yid aboud of aast 10.8637778759 18.8725502491\n",
      "0.82 Abs hour wors wor ind esonf seleo hemate in to the  23.2612478733 39.6977343559\n",
      "0.84 Ass amh are levery the to tri whem ay would are ad  12.4358229637 20.8396034241\n",
      "0.86 A rego you conving as theaclibe pomed iter ist your 14.4999480247 23.2368710041\n",
      "0.88 An ellatyiver as chase is and sci on polles in than 13.3250160217 21.2266175747\n",
      "0.9 Als idast to al a cours risent in thes the for prar 11.53399086 21.0735177994\n",
      "0.92 Ar inple are so pi me disiongte the cand un frany,  13.119052887 21.2565436363\n",
      "0.94 Autih aul itting clearas implass naraily our everyi 11.3431069851 19.2007772923\n",
      "0.96 Acregte it polificel re. Segenelcuse for thipe tact 13.478511095 20.7099220753\n",
      "0.98 Amos nacek that of coce pont pamaition ternthol ade 13.3909709454 23.5158843994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/uhellsc/anaconda/lib/python2.7/site-packages/IPython/kernel/__main__.py:8: RuntimeWarning: overflow encountered in exp\n",
      "/Users/uhellsc/anaconda/lib/python2.7/site-packages/IPython/kernel/__main__.py:9: RuntimeWarning: invalid value encountered in divide\n"
     ]
    }
   ],
   "source": [
    "optimizer = optimizers.SGD(lr=0.01)\n",
    "optimizer.setup(model.collect_parameters())\n",
    "optimizer.zero_grads()\n",
    "train(texts[:10000], optimizer, batchsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'le a a wenel mor to can and as in this acte and be '"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sentence(\"l\", temp=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
